{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import BCEWithLogitsLoss \n",
    "\n",
    "# Configurations\n",
    "base_path = os.getcwd()\n",
    "save_path = os.path.join(base_path, \"out\")\n",
    "\n",
    "noise_size = 50\n",
    "batch_size = 32\n",
    "image_size = 64\n",
    "image_channel_size = 4\n",
    "layer_base_width = 64\n",
    "\n",
    "initial_learning_rate = 0.0002\n",
    "min_learning_rate = initial_learning_rate / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The Data\n",
    "from importlib import reload\n",
    "from enum import auto, Enum\n",
    "from model import dataset \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "reload(dataset)\n",
    "\n",
    "class Category(Enum):\n",
    "    MOB = auto()\n",
    "    NPC = auto()\n",
    "    \n",
    "category = Category.NPC\n",
    "train_path = os.path.join(base_path, f\"train\\\\{category.name}\")\n",
    "\n",
    "transformer = dataset.get_transformer(image_size, image_channel_size)\n",
    "training_set = dataset.Data(train_path, category, image_channel_size, transformer)\n",
    "training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "training_loader.show_samples(num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import model.adversary as adversary_module\n",
    "import model.generator as generator_module\n",
    "import model.discriminator as discriminator_module\n",
    "import model.training as training_module\n",
    "import model.log as log_module\n",
    "\n",
    "reload(log_module)\n",
    "reload(adversary_module)\n",
    "reload(generator_module)\n",
    "reload(discriminator_module)\n",
    "reload(training_module)\n",
    "\n",
    "\n",
    "def get_generator():\n",
    "    generator = generator_module.Generator(noise_size, image_size, image_channel_size, layer_base_width)\n",
    "    generator.add_linear_layer(out_factor=8)\n",
    "    generator.add_block(in_factor=8, out_factor=4)\n",
    "    generator.add_block(in_factor=4, out_factor=2)\n",
    "    generator.add_block(in_factor=2, out_factor=1)\n",
    "    generator.add_convolutional_layer(in_size=generator.base_width, out_size=image_channel_size)\n",
    "    generator.build()\n",
    "\n",
    "    generator.set_optimizer(learning_rate=initial_learning_rate)\n",
    "    generator.set_scheduler(min_lr=min_learning_rate)\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def get_discriminator(generator):\n",
    "    discriminator = discriminator_module.Discriminator(noise_size, image_size, image_channel_size, layer_base_width)\n",
    "    discriminator.add_convolutional_layer(in_size=image_channel_size, out_size=generator.base_width)\n",
    "    discriminator.add_activator_layer()\n",
    "    discriminator.add_block(in_factor=1, out_factor=2,)\n",
    "    discriminator.add_block(in_factor=2, out_factor=4)\n",
    "    discriminator.add_block(in_factor=4, out_factor=8)\n",
    "    discriminator.add_mini_batch_layer(in_factor=8, out_factor=9, inter_value=10)\n",
    "    discriminator.add_linear_layer(in_factor=9)\n",
    "    discriminator.build()\n",
    "\n",
    "    discriminator.set_optimizer(learning_rate=initial_learning_rate)\n",
    "    discriminator.set_scheduler(min_lr=min_learning_rate)\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "\n",
    "configuration = {\n",
    "    \"data\": training_loader,\n",
    "    \n",
    "    # Image Configurations\n",
    "    \"batch_size\": batch_size,\n",
    "    \"noise_size\": noise_size, \n",
    "    \"image_size\": image_size,\n",
    "    \"image_channel_size\": image_channel_size,\n",
    "    \n",
    "    # Training Configurations\n",
    "    \"num_epochs\": 500,\n",
    "    \"initial_learning_rate\": initial_learning_rate,\n",
    "    \"min_learning_rate\": min_learning_rate,\n",
    "    \"label_smoothing_value\": 0.9,\n",
    "    \"gradient_clip_value\": 1.0,\n",
    "    \"use_mixed_precision\": True,\n",
    "    \"loss_function\": BCEWithLogitsLoss(),\n",
    "    \"generator_train_frequency\": 1,\n",
    "    \"discriminator_train_frequency\": 1,\n",
    "    \"max_train_frequency\": 3,\n",
    "    \n",
    "    # Sampling Configurations\n",
    "    \"sample_size\": 10,\n",
    "    \n",
    "    # Model Saving Configurations\n",
    "    \"out_path\": \"out\",\n",
    "    \"use_logging\": True,\n",
    "    \"save_model_interval\": 0,\n",
    "    \"save_sample_interval\": 20,\n",
    "    \"save_loss_plot\": True,\n",
    "    \"save_configuration\": True,\n",
    "    \"delete_previous_saves\": False,\n",
    "}\n",
    "\n",
    "# print(generator, \"\\n\")\n",
    "# print(discriminator)\n",
    "\n",
    "for noise_size in [50]:\n",
    "    configuration[\"noise_size\"] = noise_size\n",
    "    generator = get_generator()\n",
    "    discriminator = get_discriminator(generator)\n",
    "    trainer = training_module.Trainer(training_loader, generator, discriminator, configuration)\n",
    "    trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
